{"ast":null,"code":"/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { atomicAddSnippet } from './shader_util';\nimport { getMainHeaderString as main } from './webgpu_program';\nimport { computeDispatch, flatDispatchLayout } from './webgpu_util';\nexport class Dilation2DBackpropInputProgram {\n  constructor(convInfo, outputDtype) {\n    this.variableNames = ['x', 'w', 'dy'];\n    this.uniforms = 'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>, dySize: i32,';\n    this.workgroupSize = [64, 1, 1];\n    this.atomic = true;\n    this.outputShape = convInfo.inShape;\n    this.dispatchLayout = flatDispatchLayout(convInfo.outShape);\n    this.dispatch = computeDispatch(this.dispatchLayout, convInfo.outShape, this.workgroupSize);\n    if (outputDtype !== 'float32' && outputDtype !== 'int32') {\n      throw new Error(`Dilation2DBackpropInput only supports float32 and int32\n          types, does not support ${outputDtype} type.`);\n    }\n    this.type = outputDtype;\n    this.shaderKey = 'dilation2DBackpropInput';\n  }\n  getUserCode() {\n    // This implementation follows the TF c++ cuda implementation:\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dilation_ops_gpu.cu.cc\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.dySize) {\n           let coords = getDyCoordsFromIndex(index);\n           let b = coords[0];\n           let r = coords[1];\n           let c = coords[2];\n           let d = coords[3];\n\n           let dyCorner = vec2<i32>(r, c) * uniforms.strides - uniforms.pads;\n           var curVal = -3.4e38;  // neg_infinity\n           var xRMax = 0;\n           var xCMax = 0;\n\n           // In the case of multiple argmax branches, we only back-propagate\n           // along the last branch, i.e., the one with largest value of\n           // 'wR * uniforms.filterDims[1] + wC', similarly to the max-pooling\n           // backward routines.\n           for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {\n             let xR = dyCorner.x + wR * uniforms.dilations[0];\n\n             if (xR >= 0 && xR < uniforms.xShape[1]) {\n               for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {\n                 let xC = dyCorner.y + wC * uniforms.dilations[1];\n\n                 if (xC >= 0 && xC < uniforms.xShape[2]) {\n                   let val = getX(b, xR, xC, d) + getW(wR, wC, d);\n                   if (val > curVal) {\n                     curVal = val;\n                     xRMax = xR;\n                     xCMax = xC;\n                   }\n                 }\n               }\n             }\n           }\n\n           let flatIndexIn = d + uniforms.xShape[3] *\n               (xCMax + uniforms.xShape[2] * (xRMax + uniforms.xShape[1] * b));\n           let value = getDy(b, r, c, d);\n           ${atomicAddSnippet('&result[flatIndexIn]', 'value', this.type)}\n         }\n       }\n     `;\n    return userCode;\n  }\n}\nexport class Dilation2DBackpropFilterProgram {\n  constructor(convInfo, shape, outputDtype) {\n    this.variableNames = ['x', 'w', 'dy'];\n    this.uniforms = 'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>, dySize: i32,';\n    this.workgroupSize = [64, 1, 1];\n    this.atomic = true;\n    this.outputShape = convInfo.filterShape;\n    this.dispatchLayout = flatDispatchLayout(convInfo.outShape);\n    this.dispatch = computeDispatch(this.dispatchLayout, convInfo.outShape, this.workgroupSize);\n    if (outputDtype !== 'float32' && outputDtype !== 'int32') {\n      throw new Error(`Dilation2DBackpropFilter only supports float32 and int32\n          types, does not support ${outputDtype} type.`);\n    }\n    this.type = outputDtype;\n    this.shaderKey = 'dilation2DBackpropFilter';\n  }\n  getUserCode() {\n    // This implementation follows the TF c++ cuda implementation:\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dilation_ops_gpu.cu.cc\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.dySize) {\n           let coords = getDyCoordsFromIndex(index);\n           let b = coords[0];\n           let r = coords[1];\n           let c = coords[2];\n           let d = coords[3];\n\n           let dyCorner = vec2<i32>(r, c) * uniforms.strides - uniforms.pads;\n           var curVal = -3.4e38;  // neg_infinity\n           var wRMax = 0;\n           var wCMax = 0;\n\n           // In the case of multiple argmax branches, we only back-propagate\n           // along the last branch, i.e., the one with largest value of\n           // 'wR * uniforms.filterDims[1] + wC', similarly to the max-pooling\n           // backward routines.\n           for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {\n             let xR = dyCorner.x + wR * uniforms.dilations[0];\n\n             if (xR >= 0 && xR < uniforms.xShape[1]) {\n               for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {\n                 let xC = dyCorner.y + wC * uniforms.dilations[1];\n\n                 if (xC >= 0 && xC < uniforms.xShape[2]) {\n                   let val = getX(b, xR, xC, d) + getW(wR, wC, d);\n                   if (val > curVal) {\n                     curVal = val;\n                     wRMax = wR;\n                     wCMax = wC;\n                   }\n                 }\n               }\n             }\n           }\n\n           let flatIndexIn = d + uniforms.wShape[2] * (wCMax + wRMax * uniforms.wShape[1]);\n           let value = getDy(b, r, c, d);\n           ${atomicAddSnippet('&result[flatIndexIn]', 'value', this.type)}\n         }\n       }\n     `;\n    return userCode;\n  }\n}","map":{"version":3,"names":["atomicAddSnippet","getMainHeaderString","main","computeDispatch","flatDispatchLayout","Dilation2DBackpropInputProgram","constructor","convInfo","outputDtype","variableNames","uniforms","workgroupSize","atomic","outputShape","inShape","dispatchLayout","outShape","dispatch","Error","type","shaderKey","getUserCode","userCode","Dilation2DBackpropFilterProgram","shape","filterShape"],"sources":["C:\\Users\\PC\\Desktop\\CodingStuff\\BuildSpace\\tfjs-backend-webgpu\\src\\dilation_backprop_webgpu.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType} from '@tensorflow/tfjs-core';\n\nimport {atomicAddSnippet} from './shader_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Dilation2DBackpropInputProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'w', 'dy'];\n  uniforms =\n      'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>, dySize: i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  type: DataType;\n\n  constructor(convInfo: backend_util.Conv2DInfo, outputDtype: DataType) {\n    this.outputShape = convInfo.inShape;\n    this.dispatchLayout = flatDispatchLayout(convInfo.outShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, convInfo.outShape, this.workgroupSize);\n\n    if (outputDtype !== 'float32' && outputDtype !== 'int32') {\n      throw new Error(`Dilation2DBackpropInput only supports float32 and int32\n          types, does not support ${outputDtype} type.`);\n    }\n    this.type = outputDtype;\n    this.shaderKey = 'dilation2DBackpropInput';\n  }\n\n  getUserCode(): string {\n    // This implementation follows the TF c++ cuda implementation:\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dilation_ops_gpu.cu.cc\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.dySize) {\n           let coords = getDyCoordsFromIndex(index);\n           let b = coords[0];\n           let r = coords[1];\n           let c = coords[2];\n           let d = coords[3];\n\n           let dyCorner = vec2<i32>(r, c) * uniforms.strides - uniforms.pads;\n           var curVal = -3.4e38;  // neg_infinity\n           var xRMax = 0;\n           var xCMax = 0;\n\n           // In the case of multiple argmax branches, we only back-propagate\n           // along the last branch, i.e., the one with largest value of\n           // 'wR * uniforms.filterDims[1] + wC', similarly to the max-pooling\n           // backward routines.\n           for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {\n             let xR = dyCorner.x + wR * uniforms.dilations[0];\n\n             if (xR >= 0 && xR < uniforms.xShape[1]) {\n               for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {\n                 let xC = dyCorner.y + wC * uniforms.dilations[1];\n\n                 if (xC >= 0 && xC < uniforms.xShape[2]) {\n                   let val = getX(b, xR, xC, d) + getW(wR, wC, d);\n                   if (val > curVal) {\n                     curVal = val;\n                     xRMax = xR;\n                     xCMax = xC;\n                   }\n                 }\n               }\n             }\n           }\n\n           let flatIndexIn = d + uniforms.xShape[3] *\n               (xCMax + uniforms.xShape[2] * (xRMax + uniforms.xShape[1] * b));\n           let value = getDy(b, r, c, d);\n           ${\n        atomicAddSnippet(\n            '&result[flatIndexIn]', 'value', this.type as 'float32' | 'int32')}\n         }\n       }\n     `;\n    return userCode;\n  }\n}\n\nexport class Dilation2DBackpropFilterProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'w', 'dy'];\n  uniforms =\n      'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>, dySize: i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  type: DataType;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, shape: number[],\n      outputDtype: DataType) {\n    this.outputShape = convInfo.filterShape;\n    this.dispatchLayout = flatDispatchLayout(convInfo.outShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, convInfo.outShape, this.workgroupSize);\n\n    if (outputDtype !== 'float32' && outputDtype !== 'int32') {\n      throw new Error(`Dilation2DBackpropFilter only supports float32 and int32\n          types, does not support ${outputDtype} type.`);\n    }\n    this.type = outputDtype;\n    this.shaderKey = 'dilation2DBackpropFilter';\n  }\n\n  getUserCode(): string {\n    // This implementation follows the TF c++ cuda implementation:\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dilation_ops_gpu.cu.cc\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.dySize) {\n           let coords = getDyCoordsFromIndex(index);\n           let b = coords[0];\n           let r = coords[1];\n           let c = coords[2];\n           let d = coords[3];\n\n           let dyCorner = vec2<i32>(r, c) * uniforms.strides - uniforms.pads;\n           var curVal = -3.4e38;  // neg_infinity\n           var wRMax = 0;\n           var wCMax = 0;\n\n           // In the case of multiple argmax branches, we only back-propagate\n           // along the last branch, i.e., the one with largest value of\n           // 'wR * uniforms.filterDims[1] + wC', similarly to the max-pooling\n           // backward routines.\n           for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {\n             let xR = dyCorner.x + wR * uniforms.dilations[0];\n\n             if (xR >= 0 && xR < uniforms.xShape[1]) {\n               for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {\n                 let xC = dyCorner.y + wC * uniforms.dilations[1];\n\n                 if (xC >= 0 && xC < uniforms.xShape[2]) {\n                   let val = getX(b, xR, xC, d) + getW(wR, wC, d);\n                   if (val > curVal) {\n                     curVal = val;\n                     wRMax = wR;\n                     wCMax = wC;\n                   }\n                 }\n               }\n             }\n           }\n\n           let flatIndexIn = d + uniforms.wShape[2] * (wCMax + wRMax * uniforms.wShape[1]);\n           let value = getDy(b, r, c, d);\n           ${\n        atomicAddSnippet(\n            '&result[flatIndexIn]', 'value', this.type as 'float32' | 'int32')}\n         }\n       }\n     `;\n    return userCode;\n  }\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAmBA,SAAQA,gBAAgB,QAAO,eAAe;AAC9C,SAAQC,mBAAmB,IAAIC,IAAI,QAAsB,kBAAkB;AAC3E,SAAQC,eAAe,EAAEC,kBAAkB,QAAO,eAAe;AAEjE,OAAM,MAAOC,8BAA8B;EAYzCC,YAAYC,QAAiC,EAAEC,WAAqB;IAPpE,KAAAC,aAAa,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,CAAC;IAChC,KAAAC,QAAQ,GACJ,gGAAgG;IACpG,KAAAC,aAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;IACpD,KAAAC,MAAM,GAAG,IAAI;IAIX,IAAI,CAACC,WAAW,GAAGN,QAAQ,CAACO,OAAO;IACnC,IAAI,CAACC,cAAc,GAAGX,kBAAkB,CAACG,QAAQ,CAACS,QAAQ,CAAC;IAC3D,IAAI,CAACC,QAAQ,GAAGd,eAAe,CAC3B,IAAI,CAACY,cAAc,EAAER,QAAQ,CAACS,QAAQ,EAAE,IAAI,CAACL,aAAa,CAAC;IAE/D,IAAIH,WAAW,KAAK,SAAS,IAAIA,WAAW,KAAK,OAAO,EAAE;MACxD,MAAM,IAAIU,KAAK,CAAC;oCACcV,WAAW,QAAQ,CAAC;;IAEpD,IAAI,CAACW,IAAI,GAAGX,WAAW;IACvB,IAAI,CAACY,SAAS,GAAG,yBAAyB;EAC5C;EAEAC,WAAWA,CAAA;IACT;IACA;IACA,MAAMC,QAAQ,GAAG;SACZpB,IAAI,CAAC,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;aAwCdF,gBAAgB,CACZ,sBAAsB,EAAE,OAAO,EAAE,IAAI,CAACmB,IAA2B,CAAC;;;MAGxE;IACF,OAAOG,QAAQ;EACjB;;AAGF,OAAM,MAAOC,+BAA+B;EAY1CjB,YACIC,QAAiC,EAAEiB,KAAe,EAClDhB,WAAqB;IATzB,KAAAC,aAAa,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,CAAC;IAChC,KAAAC,QAAQ,GACJ,gGAAgG;IACpG,KAAAC,aAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;IACpD,KAAAC,MAAM,GAAG,IAAI;IAMX,IAAI,CAACC,WAAW,GAAGN,QAAQ,CAACkB,WAAW;IACvC,IAAI,CAACV,cAAc,GAAGX,kBAAkB,CAACG,QAAQ,CAACS,QAAQ,CAAC;IAC3D,IAAI,CAACC,QAAQ,GAAGd,eAAe,CAC3B,IAAI,CAACY,cAAc,EAAER,QAAQ,CAACS,QAAQ,EAAE,IAAI,CAACL,aAAa,CAAC;IAE/D,IAAIH,WAAW,KAAK,SAAS,IAAIA,WAAW,KAAK,OAAO,EAAE;MACxD,MAAM,IAAIU,KAAK,CAAC;oCACcV,WAAW,QAAQ,CAAC;;IAEpD,IAAI,CAACW,IAAI,GAAGX,WAAW;IACvB,IAAI,CAACY,SAAS,GAAG,0BAA0B;EAC7C;EAEAC,WAAWA,CAAA;IACT;IACA;IACA,MAAMC,QAAQ,GAAG;SACZpB,IAAI,CAAC,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;aAuCdF,gBAAgB,CACZ,sBAAsB,EAAE,OAAO,EAAE,IAAI,CAACmB,IAA2B,CAAC;;;MAGxE;IACF,OAAOG,QAAQ;EACjB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}